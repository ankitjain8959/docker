# Docker port mapping 
## How to run a Docker container on a specific port?
When running a Docker container, you can map the container's internal port to a specific port on the host machine using the `-p` flag. <br>
`docker run -p <host_port>:<container_port> my-image` <br>

Where: <br>
- <host_port> is the port on the host machine (i.e. your computer). <br>
- <container_port> is the port on the container (inside Docker). <br>

## How to run two different Docker images of the same Spring Boot application on separate ports locally?
You can run multiple instances of the same Spring Boot application locally on Docker by binding each container to a different host port (or your computer's port). <br>
This allows you to access them independently via different localhost ports.

- Step 1: Build Two Different Docker Images <br>
If you have made different changes to each version of your Spring Boot application, build two separate images with different tags. <br>

> Build Image 1 (First Version)
>> `docker build -t my-spring-boot-app:v1 .`

> Build Image 2 (Second Version with changes)
>> `docker build -t my-spring-boot-app:v2 .`

- Step 2: Run Two Docker Containers <br>
Since both images expose the same internal port (8080), you must map them to different host ports: <br>
> `docker run -d -p 8081:8080 my-spring-boot-app:v1` <br>
> `docker run -d -p 8082:8080 my-spring-boot-app:v2` <br>

- Step 3: Access the Applications <br>
You can now access both versions of your Spring Boot application using the following URLs: <br>
> http://localhost:8081 <br>
> http://localhost:8082 <br>

## How to expose multiple ports in a Docker container?
To expose multiple ports in a Docker container, you can use the `-p` flag multiple times to map each port to a different host port. <br>
`docker run -p <host_port_1>:<container_port_1> -p <host_port_2>:<container_port_2> my-image` <br>

For example, to expose ports 8080 and 8081 on the host machine to ports 8080 and 8081 on the container, you can use: <br>
`docker run -p 8080:8080 -p 8081:8081 my-image` <br>

This allows you to access the container on both ports from the host machine. <br>

# Docker network
Networks are used to enable communication between containers.

## How to create network aand enable communication between containers?
**Step 1:** Create a custom docker network
`docker network create lambda-mongo-net`

This will allow containers to refer to each other by name. <br>

**Step 2:** Run all containers in the same network to enable communication
```
docker run --name my-mongo --network lambda-mongo-net -d -p 27017:27017 mongo
```

# Docker Volume
## What is a Docker Volume?
Containers use volumes to store data generated by and used by containers.
All data in a container is lost when the container is removed. Containers use volumes to persist/store data. <br>

## What is Volume Mounting?
Volume mounting is the process of attaching a Docker volume (or a host directory) to a specific location inside a container.
It enables data (files & folders) sharing between a host machine and a container & between containers. <br>

- Sharing data between host (eg, local physical machine) and container: -v host_location:container_location <br>
Meaning, the host_location is mounted to the container_location. <br>

- Sharing data between containers: --volumes-from container_that_shares_data <br>
Meaning, the container_that_shares_data shares its volumes with the current container. <br>

## How to do volume mounting in Docker?
To mount a volume in Docker, you can use the `-v` flag followed by the host directory and the container directory. <br>
`docker run -v /host/directory:/container/directory my-image` <br>

For example, to mount the host directory `/data` to the container directory `/app/data`, you can use: <br>
`docker run -v /data:/app/data my-image` <br>

This allows the container to read and write data to the `/data` directory on the host machine. <br>

## How to do volume mounting between two containers in Docker?
To share volumes between two containers in Docker, you can use the `--volumes-from` flag followed by the name or ID of the container that shares the volumes. <br>
`docker run --volumes-from container-that-shares-data my-image` <br>

For example, to share volumes from a container named `data-container` with another container, you can use: <br>
`docker run --volumes-from data-container my-image` <br>

This allows the new container to access the volumes mounted in the `data-container`. <br>


# Docker caching & layering
Docker optimizes builds using layering and caching, making image creation faster and more efficient.

## How does Docker layering work?
- Every docker image consists of multiple layers.
- Each instruction in a Dockerfile (like FROM, RUN, COPY) creates a new layer in the image.

```
FROM ubuntu:latest              # Layer 1 (Base Image)
RUN apt-get update              # Layer 2
RUN apt-get install -y curl     # Layer 3
COPY . /app                     # Layer 4
CMD ["bash"]                    # Layer 5 (Final layer)
```

## What is Docker caching?
- Docker caches each layer so that if an instruction does not change, it reuses the existing layer instead of rebuilding it.
- This speeds up the build process by only rebuilding the modified layers and the ones that depend on them.

How caching works: <br>
- If a line in the Dockerfile remains the same, Docker uses the cached layer.
- If a layer changes, Docker rebuilds that layer and all layers after it.

```
FROM ubuntu:latest              # Cached if unchanged
RUN apt-get update              # Cached if unchanged
RUN apt-get install -y curl     # Cached if unchanged
COPY . /app                     # Not cached if files in `.` change
CMD ["bash"]                    # Cached if unchanged
```

If you modify the COPY . /app step, Docker rebuilds that step and everything after it. <br>

## How to leverage Docker caching for faster builds?
To leverage Docker caching for faster builds, you can reorder the instructions in your Dockerfile so that the least frequently changing instructions are placed at the top. <br>
This allows Docker to reuse cached layers for those instructions, speeding up the build process. <br>


# Docker registry?
## What is a Docker registry?
A Docker registry is a storage and distribution system (or, an application) for Docker images.
It allows you to store and share Docker images with others, making it easy to distribute and deploy applications using containers. <br>

## What is docker's default registry?
Docker's default registry is Docker Hub, a public registry that hosts a wide variety of Docker images that can be freely accessed by anyone.
When you use the `docker pull` or `docker run` commands without specifying a registry URL, Docker pulls images from Docker Hub by default. <br>

## Types of Docker registries?
1. Public Registry: A public registry is open to the public and allows anyone to push and pull images.
2. Private Registry: A private registry is restricted to authorized users and provides additional security and control over the images stored in the registry. <br>

Examples: <br>
- Docker Hub: The default public registry for Docker images.
- Amazon Elastic Container Registry (ECR)/Google Container Registry (GCR)/Azure Container Registry (ACR): A private registry service provided by AWS/Google Cloud/Microsoft Azure.
- quay.io: A container registry service provided by Red Hat that supports both public and private registries. <br>

## How to configure Docker to use a private registry?
To configure Docker to use a private registry, you can update the Docker daemon configuration file to include the private registry URL.
This allows Docker to pull images from the private registry by default without specifying the registry URL each time. <br>

To update the Docker daemon configuration, follow these steps: <br>
1. Edit the Docker daemon configuration file (usually located at `/etc/docker/daemon.json`). <br>
2. Add the private registry URL to the `insecure-registries` section. <br>
3. Save the configuration file and restart the Docker daemon. <br>
4. Docker will now use the private registry as the default registry for pulling images. <br>

```
{
  "insecure-registries": ["my-private-registry.com"]
}
```

Note: By default, Docker Hub is the fallback when no other registry provides the requested image. <br>


# Tagging Docker images
## How to tag a Docker image and what are the benefits of tagging a docker image?
To tag a Docker image, you can use the `docker tag` command followed by the image ID or name and the desired tag. <br>
`docker tag image-name image-name:tag` <br>

For example, to tag an image named `my-image` with the version `v1.0`, you can use: <br>
`docker tag my-image my-image:v1.0` <br>

This allows you to assign a version number or label to the image, making it easier to identify and reference the image in the future.
It helps you keep track of different versions of the image and ensures that you are using the correct version when running or sharing the image. <br>

# Additional Questions
## How to push a Docker image to a Docker hub & then pull the same?
To push a Docker image to Docker Hub, you need to follow these steps: <br>
1. Login to Docker Hub and create a repository for your images. <br>
2. Tag your local Docker image with the repository name and version. <br>
3. Push the tagged image to Docker Hub using the `docker push` command. <br>
4. Verify that the image has been pushed successfully by checking the repository on Docker Hub. <br>
5. To pull the image from Docker Hub, you can use the `docker pull` command followed by the repository name and version. <br>

## What is Alpine Linux and why is it commonly used in Docker images?
Alpine Linux is a lightweight Linux distribution that is commonly used as a base image for Docker containers.
It is known for its small size and minimalistic design, making it an ideal choice for reducing the size of Docker images. <br>

To use Alpine Linux as a base image in a Dockerfile, you can specify `alpine` as the tag for the image.
For example, to use Alpine Linux as the base image for a Java application, you can use: <br>
`FROM openjdk:8-alpine` <br>

This will use the Alpine Linux version of the OpenJDK 8 image as the base image for your Docker container. <br>

## What is a `.dockerignore` file and why is it used?
A `.dockerignore` file is used to exclude specific files and directories from being copied into a Docker image during the build process. <br>
It works similarly to a `.gitignore` file, allowing you to specify patterns to exclude files and directories. <br>

Using a `.dockerignore` file helps reduce the size of the Docker image by excluding unnecessary files and directories. <br>
This can speed up the build process and reduce the size of the final image, making it more efficient to work with. <br>

## How to reduce the size of a Docker image? or, How to optimize Docker image build time?
To reduce the size of a Docker image, you can follow these best practices: <br>
1. Remove unnecessary files and directories using a `.dockerignore` file. <br>
2. Use a smaller base image, such as Alpine Linux, instead of a full OS image. <br>
3. Combine multiple `RUN` commands into a single `RUN` command to reduce the number of layers and therefore speed up the build process. <br>
4. Put frequently changing instructions at the bottom of the Dockerfile to take advantage of caching. <br>

## How to write a multi line RUN command in Dockerfile to speed up build time?
To write a multi-line `RUN` command in a Dockerfile, you can use the backslash `\` character at the end of each line to continue the command on the next line.
This allows you to break a long command into multiple lines for better readability. <br>

For example, to install multiple packages in a single `RUN` command, you can use: <br>
```
RUN apt-get update && \
    apt-get install -y package1 package2 package3
```

This reduces the number of layers created in the image, which can speed up the build process by leveraging Docker's layer caching mechanism. <br>

# Best Practices
- Tag your Docker images with version numbers.
- Use a `.dockerignore` file to exclude unnecessary files.
- Combine multiple `RUN` commands into a single `RUN` command.
- Put frequently changing instructions at the bottom of the Dockerfile.
- Use a smaller base image, such as Alpine Linux.
- Leverage Docker caching for faster builds.
